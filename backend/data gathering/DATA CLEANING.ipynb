{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7682d28",
   "metadata": {},
   "source": [
    "\n",
    "# Data Processing and Extraction using NLP\n",
    "This notebook processes textual data, identifies important sentences using Natural Language Processing (NLP), \n",
    "and exports the results to a CSV file. The dataset used contains various text snippets, and our goal is to \n",
    "extract important information by recognizing entities and other key aspects.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "38ca4e61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:51:15.282435Z",
     "start_time": "2024-10-17T09:51:12.020921Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "# Load spaCy model (Dutch language model for this case)\n",
    "nlp = spacy.load(\"nl_core_news_lg\")\n",
    "\n",
    "# Enable GPU usage for spaCy if available\n",
    "spacy.prefer_gpu()\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "baae5cc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:51:16.496198Z",
     "start_time": "2024-10-17T09:51:15.284990Z"
    }
   },
   "source": [
    "# Load the dataset\n",
    "try:\n",
    "    df = pd.read_csv('Antwerpen_c_2.csv')\n",
    "    print(\"Dataset loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset file not found.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "9c6a2a58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T09:51:16.504681Z",
     "start_time": "2024-10-17T09:51:16.497415Z"
    }
   },
   "source": [
    "# Split the text into sentences using regex for sentence boundary detection\n",
    "def split_sentences(text):\n",
    "    # Pattern matches sentence boundaries after punctuation followed by a capital letter\n",
    "    sentence_pattern = r'(?<=[.!?])\\s+(?=[A-Z])'\n",
    "    sentences = re.split(sentence_pattern, text)\n",
    "    return sentences\n",
    "\n",
    "# Define a function to determine if a sentence is important\n",
    "def is_important(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Check for named entities\n",
    "    if len(doc.ents) > 0:\n",
    "        return True\n",
    "    \n",
    "    # Check if the sentence length is within a reasonable range\n",
    "    if 3 < len(doc) < 30:\n",
    "        return True\n",
    "\n",
    "    # Check for specific parts of speech such as proper nouns or numbers\n",
    "    if any(token.pos_ == 'PROPN' or token.pos_ == 'NUM' for token in doc):\n",
    "        return True\n",
    "    \n",
    "    return False\n",
    "\n",
    "\n",
    "\n",
    "# Ensure consistent results\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def is_dutch(text):\n",
    "    try:\n",
    "        language = detect(text)\n",
    "        if language == 'nl':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "a2faa35b",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-17T09:51:16.506991Z"
    }
   },
   "source": [
    "\n",
    "# Process all sentences in the dataframe\n",
    "all_sentences = []\n",
    "\n",
    "for text in df['body_content']:\n",
    "    sentences = split_sentences(text)\n",
    "    all_sentences.extend(sentences)\n",
    "\n",
    "# Create a DataFrame for sentences\n",
    "sentences_df = pd.DataFrame(all_sentences, columns=['sentence'])\n",
    "\n",
    "# Remove duplicate sentences\n",
    "sentences_df = sentences_df.drop_duplicates(subset='sentence')\n",
    "\n",
    "# Mark important sentences\n",
    "sentences_df['important'] = sentences_df['sentence'].apply(is_important)\n",
    "\n",
    "# Filter only important sentences\n",
    "important_sentences_df = sentences_df[sentences_df['important'] == True].drop(columns=['important'])\n",
    "\n",
    "sentences_df['dutch'] = sentences_df['sentence'].apply(is_dutch)\n",
    "\n",
    "dutch_sentences_df = sentences_df[sentences_df['dutch'] == True].drop(columns=['dutch'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "keywords=['browser','menu','contact','2020 antwerpen','sportcentrum','bel','surf','ook interessant','locatie',':','telefoneer','schrijf','website','aanbod','gezin','euro','mail','tel+','@','€','stadsplan','leaflet','gemeentearchief','cookie', 'NL','internetbrowser','E-mail','©','™','|']\n",
    "\n",
    "pattern = '|'.join(keywords)\n",
    "\n",
    "important_sentences_df = important_sentences_df[~important_sentences_df['sentence'].str.contains(pattern, case=False)]"
   ],
   "id": "17682ec58f07e672",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "average_length = important_sentences_df['sentence'].str.len().mean()\n",
    "\n",
    "important_sentences_df = important_sentences_df[important_sentences_df['sentence'].str.len() >= average_length-18]"
   ],
   "id": "8db033b96bf1c64e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": "important_sentences_df.reset_index(drop=True, inplace=True)",
   "id": "5edf60ee0866f676",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73e07ed4",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Export important sentences to a CSV file\n",
    "important_sentences_df.to_csv('important_sentences.csv', index=True)\n",
    "print(\"Important sentences exported successfully.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e6009995",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Display a few important sentences\n",
    "important_sentences_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
